{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "from keras import models, layers, callbacks\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "  def __init__(\n",
    "      self,\n",
    "      dataset_path: str = \"../datasets/\",\n",
    "      story_path: str = \"../datasets/CBU0521DD_stories/\",\n",
    "      augmented_story_path: str = \"../datasets/CBU0521DD_stories/_augmented/\",\n",
    "      label_path: str = \"../datasets/CBU0521DD_stories_attributes.csv\",\n",
    "      augmented_label_path: str = \"../datasets/CBU0521DD_stories_attributes_augmented.csv\",\n",
    "      model_path: str = \"../models/\",\n",
    "      epoch: int = 100,\n",
    "      batch_size: int = 10,\n",
    "  ):\n",
    "    self.dataset_path = dataset_path\n",
    "    self.story_path = story_path\n",
    "    self.augmented_story_path = augmented_story_path\n",
    "    self.label_path = label_path\n",
    "    self.augmented_label_path = augmented_label_path\n",
    "    self.model_path = model_path\n",
    "    self.epoch = epoch\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "config = Config(\n",
    "    dataset_path=\"../datasets/\",\n",
    "    story_path=\"../datasets/CBU0521DD_stories/\",\n",
    "    augmented_story_path=\"../datasets/CBU0521DD_stories/_augmented/\",\n",
    "    label_path=\"../datasets/CBU0521DD_stories_attributes.csv\",\n",
    "    augmented_label_path=\"../datasets/CBU0521DD_stories_attributes_augmented.csv\",\n",
    "    model_path=\"../models/\",\n",
    "    epoch=100,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "  \"\"\"\n",
    "  用于完成以下功能：\n",
    "  1. 读取并加载数据（包括原始数据与增强数据）\n",
    "  2. 对音频数据进行特征提取（Mel-Spectrogram, MFCC, Chroma等）\n",
    "  3. 保存与加载NPZ格式的数据\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config: Config):\n",
    "    self.config = config\n",
    "\n",
    "  def load_data(\n",
    "      self,\n",
    "      dataset_path: str,\n",
    "      labels_df: pd.DataFrame,\n",
    "      augmented: bool = False\n",
    "  ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    augmented=True时，读取增强后的数据及标签，否则读取原始数据。\n",
    "    返回 features, labels\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    if augmented:\n",
    "      augmented_labels_df = pd.read_csv(self.config.augmented_label_path)\n",
    "      filenames = augmented_labels_df[\"filename\"].tolist()\n",
    "    else:\n",
    "      filenames = labels_df[\"filename\"].tolist()\n",
    "\n",
    "    for filename in tqdm(filenames, desc=\"Loading data\", ncols=100, unit=\"file\"):\n",
    "      file_path = os.path.join(dataset_path, filename)\n",
    "      audio_features = self.extract_features(file_path)\n",
    "\n",
    "      if augmented:\n",
    "        story_type = augmented_labels_df[\n",
    "            augmented_labels_df[\"filename\"] == filename\n",
    "        ][\"Story_type\"].values[0]\n",
    "      else:\n",
    "        story_type = labels_df[\n",
    "            labels_df[\"filename\"] == filename\n",
    "        ][\"Story_type\"].values[0]\n",
    "\n",
    "      features.append(audio_features)\n",
    "      labels.append(story_type)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "  @staticmethod\n",
    "  def extract_features(\n",
    "      file_path: str,\n",
    "      sr: int = 16000,\n",
    "      n_mels: int = 128,\n",
    "      duration: int = 240,\n",
    "  ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    提取音频特征，包括Mel-Spectrogram、MFCC、Chroma、ZCR、能量、持续时间、谱质心、滚降点等。\n",
    "    最终将所有特征拼接到同一矩阵中，并做定长处理。\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_mels=n_mels\n",
    "    )\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20)\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    short_term_energy = np.sum(audio ** 2) / len(audio)\n",
    "    duration_feature = len(audio) / sr\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)\n",
    "    spectral_flux = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "\n",
    "    features = np.vstack([\n",
    "        log_mel_spectrogram,\n",
    "        mfcc,\n",
    "        chroma,\n",
    "        zero_crossing_rate,\n",
    "        spectral_centroid,\n",
    "        spectral_rolloff,\n",
    "        spectral_flux,\n",
    "    ])\n",
    "\n",
    "    target_length = int(sr * duration / 512)\n",
    "    if features.shape[1] < target_length:\n",
    "      padding = np.zeros((features.shape[0], target_length - features.shape[1]))\n",
    "      features = np.concatenate([features, padding], axis=1)\n",
    "    else:\n",
    "      features = features[:, :target_length]\n",
    "\n",
    "    additional_features = np.array([short_term_energy, duration_feature])\n",
    "    additional_features = np.repeat(additional_features[:, np.newaxis], features.shape[1], axis=1)\n",
    "    \n",
    "    features = np.concatenate([features, additional_features], axis=0)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(features: np.ndarray, labels: np.ndarray, file_path: str) -> None:\n",
    "  np.savez(file_path, features=features, labels=labels)\n",
    "  print(f\"Dataset saved to: {file_path}\")\n",
    "\n",
    "def load_data_from_npz(file_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "  data = np.load(file_path)\n",
    "  return data[\"features\"], data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "  \"\"\"\n",
    "  负责构建与返回所需模型。\n",
    "  目前包含：CNN-LSTM模型（带Attention）以及随机森林模型。\n",
    "  \"\"\"\n",
    "  def build_cnn_lstm_model(self, input_shape: Tuple[int, int, int]) -> models.Model:\n",
    "    model_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(model_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Reshape((1, 128))(x)  # (batch_size, sequence_length=1, feature_dim=128)\n",
    "    attention_output = layers.Attention()([x, x])  # Self-Attention\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(attention_output)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=model_input, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "  @staticmethod\n",
    "  def build_rf_model(random_state: int = 42, n_estimators: int = 100) -> RandomForestClassifier:\n",
    "    return RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "  \"\"\"\n",
    "  负责模型的训练与可视化（如Loss、Accuracy曲线）。\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config: Config, model_builder: ModelBuilder):\n",
    "    self.config = config\n",
    "    self.model_builder = model_builder\n",
    "    self.models_list: List[models.Model] = []\n",
    "    self.rf_model: Optional[RandomForestClassifier] = None\n",
    "\n",
    "  @staticmethod\n",
    "  def show_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "  def train_cnn_lstm_ensemble(\n",
    "      self,\n",
    "      X_train: np.ndarray,\n",
    "      y_train: np.ndarray,\n",
    "      X_val: np.ndarray,\n",
    "      y_val: np.ndarray,\n",
    "      n_models: int = 3,\n",
    "      continue_training: bool = False\n",
    "  ) -> List[models.Model]:\n",
    "    \"\"\"\n",
    "    训练多个CNN-LSTM模型（集成），或加载已有模型继续训练。\n",
    "    \"\"\"\n",
    "    if continue_training:\n",
    "      for i in range(n_models):\n",
    "        model_path = os.path.join(self.config.model_path, f\"best_model_{i + 1}.keras\")\n",
    "        loaded_model = load_model(model_path)\n",
    "        self.models_list.append(loaded_model)\n",
    "    else:\n",
    "      self.models_list = []\n",
    "\n",
    "    for i in range(n_models):\n",
    "      if continue_training:\n",
    "        model = self.models_list[i]\n",
    "        print(f\"继续训练Model {i+1}\")\n",
    "      else:\n",
    "        print(f\"训练Model {i+1}\")\n",
    "        model = self.model_builder.build_cnn_lstm_model(\n",
    "            (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "        )\n",
    "\n",
    "      early_stopping = callbacks.EarlyStopping(monitor=\"loss\", patience=100)\n",
    "      model_checkpoint = callbacks.ModelCheckpoint(\n",
    "          filepath=os.path.join(self.config.model_path, f\"best_model_{i + 1}.keras\"),\n",
    "          monitor=\"val_accuracy\",\n",
    "          save_best_only=True\n",
    "      )\n",
    "      callbacks_list = [early_stopping, model_checkpoint]\n",
    "\n",
    "      history = model.fit(\n",
    "          X_train,\n",
    "          y_train,\n",
    "          epochs=self.config.epoch,\n",
    "          batch_size=self.config.batch_size,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=callbacks_list\n",
    "      )\n",
    "      self.show_history(history)\n",
    "      self.models_list.append(model)\n",
    "\n",
    "    return self.models_list\n",
    "\n",
    "  def train_random_forest(self, X_train: np.ndarray, y_train: np.ndarray) -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    训练随机森林模型。\n",
    "    \"\"\"\n",
    "    self.rf_model = self.model_builder.build_rf_model()\n",
    "    # 对高维特征进行降维处理，展开为2D\n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    self.rf_model.fit(X_train_2d, y_train)\n",
    "    return self.rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "  \"\"\"\n",
    "  用于模型预测及输出结果。包含集成预测的方法。\n",
    "  \"\"\"\n",
    "  @staticmethod\n",
    "  def ensemble_predict(\n",
    "      models_list: List[models.Model],\n",
    "      rf_model: RandomForestClassifier,\n",
    "      X_test: np.ndarray,\n",
    "      weights: Optional[List[float]] = None\n",
    "  ) -> np.ndarray:\n",
    "    nn_preds = np.zeros((len(models_list), X_test.shape[0]))\n",
    "    for i, model in enumerate(models_list):\n",
    "      nn_preds[i] = model.predict(X_test).flatten()\n",
    "\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "    rf_preds = rf_model.predict_proba(X_test_2d)[:, 1]\n",
    "\n",
    "    if weights is None:\n",
    "      weights = [1.0 / len(models_list)] * len(models_list)\n",
    "\n",
    "    nn_pred_avg = np.average(nn_preds, axis=0, weights=weights)\n",
    "\n",
    "    final_pred_prob = (nn_pred_avg + rf_preds) / 2.0\n",
    "    final_pred = (final_pred_prob > 0.5).astype(int)\n",
    "    return final_pred, final_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray, labels: List[str]):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  plt.figure(figsize=(6, 6))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "  plt.ylabel(\"Actual\")\n",
    "  plt.xlabel(\"Predicted\")\n",
    "  plt.title(\"Confusion Matrix\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true: np.ndarray, y_pred_prob: np.ndarray):\n",
    "  fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\", color=\"blue\")\n",
    "  plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")\n",
    "  plt.xlabel(\"1 - Specificity (FPR)\")\n",
    "  plt.ylabel(\"Sensitivity (TPR)\")\n",
    "  plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "  \"\"\"\n",
    "  对模型进行评估，包括指标计算、混淆矩阵与ROC曲线绘制等。\n",
    "  \"\"\"\n",
    "  @staticmethod\n",
    "  def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray) -> None:\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "\n",
    "    sensitivity = TP / (TP + FN)  # TPR\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "    print(f\"Sensitivity: {sensitivity:.2f}\")\n",
    "    print(f\"Specificity: {specificity:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "  def evaluate_ensemble_model(\n",
    "      self,\n",
    "      models_list: List[models.Model],\n",
    "      rf_model: RandomForestClassifier,\n",
    "      X_test: np.ndarray,\n",
    "      y_true: np.ndarray,\n",
    "      labels: List[str]\n",
    "  ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    final_pred, final_pred_prob = Predictor.ensemble_predict(models_list, rf_model, X_test)\n",
    "    print(\"\\nEnsemble Model Evaluation:\")\n",
    "    self.evaluate_model(y_true, final_pred)\n",
    "    plot_confusion_matrix(y_true, final_pred, labels=labels)\n",
    "    plot_roc_curve(y_true, final_pred_prob)\n",
    "    return final_pred, final_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "  def __init__(self, config: Config):\n",
    "    self.config = config\n",
    "    self.data_transformer = DataTransformer(config)\n",
    "    self.model_builder = ModelBuilder()\n",
    "    self.trainer = Trainer(config, self.model_builder)\n",
    "    self.evaluator = Evaluator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Truora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
